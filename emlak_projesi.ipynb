{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ad11ed-683e-4c82-af4c-5054e155577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zeyrek in c:\\users\\elif\\anaconda3\\lib\\site-packages (0.1.3)\n",
      "Requirement already satisfied: nltk>=3 in c:\\users\\elif\\anaconda3\\lib\\site-packages (from zeyrek) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\elif\\anaconda3\\lib\\site-packages (from nltk>=3->zeyrek) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\elif\\anaconda3\\lib\\site-packages (from nltk>=3->zeyrek) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\elif\\anaconda3\\lib\\site-packages (from nltk>=3->zeyrek) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\elif\\anaconda3\\lib\\site-packages (from nltk>=3->zeyrek) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\elif\\anaconda3\\lib\\site-packages (from click->nltk>=3->zeyrek) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install zeyrek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a34b5b7-120b-47b3-a469-a7c757d4ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from snowballstemmer import TurkishStemmer\n",
    "import zeyrek\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99a5673-a79a-4141-bcd6-c1b0f1df4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd49305f-2423-4bd9-851c-acadf34761a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARALI OLUP ÖNÜ KAPANMAZ MUHTEŞEM SAKIZ ADASI MANZARALI 2+1 , 1+1 BAHÇELİ VE TERASLI DAİRELERDEN OLUŞAN PROJEDE KAPALI OTOPARK SPOR SALONU 7/24 GÜVENLİK AKILLI VE KONTROL MAKENİZMALI EV KONTROL SİSTEMİ VE\\xa0 SONSUZLUK HAVUZU SİZLERİ BEKLİYOR.',\n",
       " '4 BLOKTAN OLUŞAN PROJEDE\\xa0 SINIRLI SAYIDA DAİRELERİMİZ KALMIŞTIR.',\n",
       " 'DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI GÖSTERMEKTEDİR.',\n",
       " 'PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAPULU OLARAK SATIŞ OLACAĞI İÇİN KREDİYE UYGUN DEĞİLDİR.',\n",
       " 'AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.',\n",
       " 'LÜTFEN DETAYLI BİLGİ İÇİN ARAYINIZ.',\n",
       " 'ÇEŞME ATİLLA EMLAK',\n",
       " 'ÇEŞME DALYAN MAHALLESİNDE\\xa0 DALYAN MARİNAYA,PLAJLARA,MARKETLERE,DOLMUŞLARA YAKIN\\xa0 KALORİFERLİ\\xa0 YAZ KIŞ OTURMAYA UYGUN 2 ODA 1 SALON\\xa0 SIFIR SATILIK DAİRE\\xa0 DETAYLI BİLGİ VE RANDEVU İÇİN LÜTFEN ARAYINIZ.',\n",
       " 'ÇEŞME ATİLLA EMLAK',\n",
       " 'ÇEŞME AYASARANDA MEVKİİNDE 712 RESİDENCE DA ÖZEL YAPIM SATILIK 2+1 DUBLEX DAİRERESIDENCE DAİREMİZ ÖZEL DİZAYN EDİLMİŞ OLUP,80M2 NET KULLANIM ALANINA SAHİPTİR.EVDE ÖZEL AJAX ALARM SİTEMİ MEVCUTTUR.MUTFAK VE TEZGAHI İTHAL MALZEMEDEN ÖZEL YAPTIRILMIŞTIR.DAİREMİZDE ANA SU HATTINDAN GİRİŞTE AYRICA İÇME SUYU ARITMASI MEVCUTTUR.AYRICA 17M2 ÖZEL DİZAYN EDİLMİŞ GİYİM ODASI OLARAK TASARLANAN KARAVAN MEVCUTTUR.ÖNÜNDE 24M2 İTHAL DEK KAPILIDIR.AYRICA OTOMATİK ALBERT GENAU PERGOLA ÜST AÇILIR MEVCUTTUR.YAN CAMLAR SÜRGÜLÜ SİSTEM,ÜSÜTÜNDE TÜM KAPI VE PENCERELERDE SİNEKLİK VARDIR.EŞYALAR FİYATA DAİL DEĞİLDİR.',\n",
       " \"ÇEŞME MUSALLA'DA MARİNAYA YÜRÜME MESAFESİNDE SATILIK LÜKS SIFIR 1+1 DAİRE TOPLAM 2417 M2 ARSA ÜZERİNDE 2 BLOKTAN OLUŞAN HAVUZLU MODERN SİTE İÇERİSİNDEDİR.\",\n",
       " 'PROJE TOPLAM 24 DAİRE İÇERMEKTEDİR.',\n",
       " 'PROJE DE 1+1, 2+1 VE 3+1 DAİRE SEÇENEKLERİ BULUNMAKTADIR.',\n",
       " \"1500 M2 BODRUM KATTA KAPALI OTOPARK ALANI VE HER DAİREYE AİT 5-9 M2'LİK DEPO ALANI GÖREVLİ DAİRESİ VE TEKNİK ALANLAR HAVUZ ALANI (250M2) VE PEYZAJ ALANI BRÜT YAŞAM ALANI 63 M2, NET KAPALI KULLANIM ALANI 55 M2 SALON, AÇIK MUTFAK, 1 ADET YATAK ODASI, GENEL BANYO VE BALKON ALANI\\u200b ASANSÖRLÜ GÜVENLİKLİ KAMERA SİSTEMİ-YANGIN ALARMI VE HAREKET SENSÖRÜ OTOMATİK PANJURLU-SİNEKLİKLİ LİNEA ROSSA 1.\",\n",
       " 'SINIF DOĞRAMALAR BANYO DA VİTRA VE GROHE MARKA 1.',\n",
       " 'SINIF BATARYA VE EVYE MUTFAK DA SIEMENS MARKA ANKASTRE SETİ VE BULAŞIK MAKİNASI YATAK ODALARINDA SAMSUNG KLİMA SALONDA VRV ISITMA-SOĞUTMA SİSTEMİ YATAK ODALARINDA GÖMME DOLAP AKILLI EV OTOMASYONU VESTİYER ALANI VE ÇAMAŞIR-KURUTMA MAKİNASI ALANI DETAYLI BİLGİ VE RANDEVU TALEBİ İÇİN LÜTFEN İLETİŞİME GEÇİNİZ.',\n",
       " 'ÇEŞME ŞİFNE YALI BÖLGESİNDE302 ARSA PAYLI5+2 280M2 BRÜT 180M2 NET KULLANIM ALANLIMÜSTAKİL VİLLAMIZ ŞÖMİNELİ OLUP MÜSTAKİL HAVUZLUDUR',\n",
       " \"COLDWELL BANKER POYRAZ GAYRİMENKULMENDERES'İN EN HUZURLU MAHALLESİ BARBAROS'TA,MÜSTAKİL YAŞAMIN TADINI ÇIKARACAĞINIZ, HAVUZLU NEZİH SİTE İÇERİSİNDEKİ VİLLAMIZIN ÖZELLİKLERİ;\\u200b*MÜSTAKİL GİRİŞ ÇIKIŞ İMKANI,*4 ODA 1 AÇIK MUTFAK SALON,*EN ALT KATTA WC,*2.KATTA 2 ODA*3.KATTA 2 ODA,*LED VE SPOT AYDINLATMALI,*3'LÜ ANKASTRE SET,*TÜM ODALARI AYDINLIK GENİŞ VE KULLANIŞLI,*EBEVEYN BANYOLU,*MÜSTAKİL BAHÇELİ,*YAZ KIŞ KULLANIMA UYGUN CAMLAMA İLE KAPATILMIŞ VARENDA,*MERDİVEN ÇIKIŞLARINDA ÇOCUK EMNİYET KAPISI,*OTOMATİK PANJUR,*ARTEZYEN,HİDRAFOR,*SİTE İÇİ ORTAK KULLANIM YEŞİL ALANLARVİLLAMIZ HAKKINDA DETAYLI BİLGİ ALMAK İÇİN LÜTFEN İLETİŞİME GEÇİNİZ..ASLI ÖZ\",\n",
       " 'ERTUĞLURDA\\nKUPON\\xa0 ACİL SATILIK\\xa0 3+1 DAİRE',\n",
       " 'Dairemiz önder cad satılık\\xa0 esyali olarak satiliktir.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veri setini yükleme\n",
    "df = pd.read_csv(\"emlakodev.csv\")\n",
    "texts = df['ilanaciklama'].dropna().tolist()\n",
    "sentences = sum([sent_tokenize(t) for t in texts], [])\n",
    "sentences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded14573-b7ad-4bb2-8abd-dec2d1a09b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sanki', 'da', 'niçin', 'birşey', 'biz', 'şu', 'hem', 'her', 'çünkü', 'ile', 'neden', 'nereye', 'nerede', 'ne', 'siz', 'birkaç', 'veya', 'tüm', 'yani', 'mu', 'defa', 'hepsi', 'nasıl', 'o', 'çok', 'acaba', 'niye', 'ki', 'mü', 'ya', 'ise', 'ama', 'mı', 'diye', 'kim', 'az', 'daha', 'kez', 'nerde', 've']\n"
     ]
    }
   ],
   "source": [
    "#stopwords listesi alma\n",
    "\n",
    "stop_words = set(stopwords.words('turkish'))\n",
    "stop_words_list = list(stop_words)\n",
    "print(stop_words_list[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d72a8dd-545c-4687-939c-6b7afa0f0486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acaba',\n",
       " 'ama',\n",
       " 'aslında',\n",
       " 'az',\n",
       " 'bazı',\n",
       " 'belki',\n",
       " 'biri',\n",
       " 'birkaç',\n",
       " 'birşey',\n",
       " 'biz',\n",
       " 'bu',\n",
       " 'da',\n",
       " 'daha',\n",
       " 'de',\n",
       " 'defa',\n",
       " 'diye',\n",
       " 'en',\n",
       " 'eğer',\n",
       " 'gibi',\n",
       " 'hem',\n",
       " 'hep',\n",
       " 'hepsi',\n",
       " 'her',\n",
       " 'hiç',\n",
       " 'ile',\n",
       " 'ise',\n",
       " 'için',\n",
       " 'kez',\n",
       " 'ki',\n",
       " 'kim',\n",
       " 'mu',\n",
       " 'mü',\n",
       " 'mı',\n",
       " 'nasıl',\n",
       " 'ne',\n",
       " 'neden',\n",
       " 'nerde',\n",
       " 'nerede',\n",
       " 'nereye',\n",
       " 'niye',\n",
       " 'niçin',\n",
       " 'o',\n",
       " 'sanki',\n",
       " 'siz',\n",
       " 'tüm',\n",
       " 've',\n",
       " 'veya',\n",
       " 'ya',\n",
       " 'yani',\n",
       " 'çok',\n",
       " 'çünkü',\n",
       " 'şey',\n",
       " 'şu'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d87ca65-cea9-475d-83f4-14df3a6f7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Türkçe NLP araçları\n",
    "lemmatizer = zeyrek.MorphAnalyzer()\n",
    "stemmer = TurkishStemmer()\n",
    "stop_words = set(stopwords.words('turkish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41605eb8-1ebb-49d7-81fc-3a4fb738d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'[^a-zA-ZçÇğĞıİöÖşŞüÜ\\s]', '', sentence)\n",
    "    tokens = word_tokenize(sentence)\n",
    "    filtered_tokens = [token for token in tokens if token.isalpha() and token not in stop_words and len(token) > 2]\n",
    "    lemmatized_tokens = []\n",
    "    for token in filtered_tokens:\n",
    "        try:\n",
    "            analysis = lemmatizer.analyze(token)\n",
    "            if analysis and analysis[0]:\n",
    "                lemma = analysis[0][0][1]\n",
    "                if lemma != 'Unk':  # Unk olmayanları ekle\n",
    "                    lemmatized_tokens.append(lemma)\n",
    "        except Exception:\n",
    "            pass  # Hata durumunda kelimeyi atla\n",
    "    stemmed_tokens = [stemmer.stemWord(token) for token in filtered_tokens]\n",
    "    return lemmatized_tokens, stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f41aeb13-09a3-40ca-9954-3099f2b3f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting sentences: 100%|██████████████████████████████████████████████████████| 2776/2776 [00:00<00:00, 4765.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample sentences: ['ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARALI OLUP ÖNÜ KAPANMAZ MUHTEŞEM SAKIZ ADASI MANZARALI 2+1 , 1+1 BAHÇELİ VE TERASLI DAİRELERDEN OLUŞAN PROJEDE KAPALI OTOPARK SPOR SALONU 7/24 GÜVENLİK AKILLI VE KONTROL MAKENİZMALI EV KONTROL SİSTEMİ VE\\xa0 SONSUZLUK HAVUZU SİZLERİ BEKLİYOR.', '4 BLOKTAN OLUŞAN PROJEDE\\xa0 SINIRLI SAYIDA DAİRELERİMİZ KALMIŞTIR.']\n",
      "\n",
      "İlk ilan: ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARALI OLUP ÖNÜ KAPANMAZ MUHTEŞEM SAKIZ ADASI MANZARALI 2+1 , 1+1 BAHÇELİ VE TERASLI DAİRELERDEN OLUŞAN PROJEDE KAPALI OTOPARK SPOR SALONU 7/24 GÜVENLİK AKILLI VE KONTROL MAKENİZMALI EV KONTROL SİSTEMİ VE  SONSUZLUK HAVUZU SİZLERİ BEKLİYOR. 4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRELERİMİZ KALMIŞTIR. DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI GÖSTERMEKTEDİR. PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAPULU OLARAK SATIŞ OLACAĞI İÇİN KREDİYE UYGUN DEĞİLDİR. AİDAT ÖDEMESİ AYLIK 2.500 TL DİR. LÜTFEN DETAYLI BİLGİ İÇİN ARAYINIZ. ÇEŞME ATİLLA EMLAK\n",
      "Cümle sayısı: 9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#cğmleleri işleme\n",
    "sentences = []\n",
    "for t in tqdm(texts, desc=\"Extracting sentences\"):\n",
    "    sentences.extend(sent_tokenize(t))\n",
    "\n",
    "print(f\"\\nSample sentences: {sentences[:2]}\\n\")\n",
    "print(f\"İlk ilan: {texts[0]}\")\n",
    "print(f\"Cümle sayısı: {len(sentences)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f58deee8-d3d9-4e70-98bb-5659e582ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample sentences: ['ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARALI OLUP ÖNÜ KAPANMAZ MUHTEŞEM SAKIZ ADASI MANZARALI 2+1 , 1+1 BAHÇELİ VE TERASLI DAİRELERDEN OLUŞAN PROJEDE KAPALI OTOPARK SPOR SALONU 7/24 GÜVENLİK AKILLI VE KONTROL MAKENİZMALI EV KONTROL SİSTEMİ VE\\xa0 SONSUZLUK HAVUZU SİZLERİ BEKLİYOR.', '4 BLOKTAN OLUŞAN PROJEDE\\xa0 SINIRLI SAYIDA DAİRELERİMİZ KALMIŞTIR.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSample sentences: {sentences[:2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b39afd6-4621-4a9e-af4a-fa1c75da51b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 1: 100%|██████████████████████████████████████████████████████████| 1000/1000 [02:19<00:00,  7.19it/s]\n",
      "Processing batch 2: 100%|██████████████████████████████████████████████████████████| 1000/1000 [02:29<00:00,  6.68it/s]\n",
      "Processing batch 3: 100%|██████████████████████████████████████████████████████████| 1000/1000 [02:08<00:00,  7.80it/s]\n",
      "Processing batch 4: 100%|██████████████████████████████████████████████████████████| 1000/1000 [01:56<00:00,  8.55it/s]\n",
      "Processing batch 5: 100%|██████████████████████████████████████████████████████████| 1000/1000 [03:01<00:00,  5.52it/s]\n",
      "Processing batch 6: 100%|██████████████████████████████████████████████████████████| 1000/1000 [02:32<00:00,  6.58it/s]\n",
      "Processing batch 7: 100%|██████████████████████████████████████████████████████████| 1000/1000 [02:20<00:00,  7.13it/s]\n",
      "Processing batch 8: 100%|██████████████████████████████████████████████████████████| 1000/1000 [02:02<00:00,  8.16it/s]\n",
      "Processing batch 9: 100%|██████████████████████████████████████████████████████████| 1000/1000 [02:02<00:00,  8.13it/s]\n",
      "Processing batch 10: 100%|███████████████████████████████████████████████████████████| 451/451 [00:53<00:00,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized sample: [['Çeşme', 'mevkii', 'Full', 'de', 'olmak', 'ön', 'kapanmak', 'muhteşem', 'Bahçe', 'daire', 'oluşmak', 'proje', 'otopark', 'spor', 'salon', 'Güvenlik', 'Akil', 'kontrol', 'kontrol', 'sistem', 'sonsuz', 'havuz', 'siz', 'beklemek'], ['blok', 'oluşmak', 'proje', 'sinirli', 'daire'], ['daire', 'göre', 'fiyat', 'göstermek'], ['proje', 'nitelik', 'olmak', 'his', 'tapu', 'olmak', 'kredi', 'uygun', 'değil'], ['aidat', 'ödemek']]\n",
      "Stemmed sample: [['çeşme', 'ayasara', 'mevkiin', 'full', 'de', 'manzarali', 'olup', 'ön', 'kapanmaz', 'muhteşe', 'sakiz', 'adasi', 'manzarali', 'bahçel', 'terasli', 'daire', 'oluşa', 'proje', 'kapali', 'otopark', 'spor', 'salo', 'güvenlik', 'akilli', 'kontrol', 'makenizmal', 'kontrol', 'siste', 'sonsuzluk', 'havuz', 'siz', 'bekliyor'], ['blok', 'oluşa', 'proje', 'sinirli', 'sayi', 'daire', 'kalmiş'], ['daire', 'konum', 'gör', 'fiyat', 'farklilik', 'göstermek'], ['proje', 'resinde', 'nitelik', 'olup', 'his', 'tapul', 'olarak', 'satiş', 'olacaği', 'kredi', 'uygu', 'değil'], ['aidat', 'ödemes', 'aylik', 'dir']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger('zeyrek').setLevel(logging.CRITICAL)  # Sadece ciddi hataları göster\n",
    "# Tokenization, lemmatization, and stemming\n",
    "tokenized_corpus_lemmatized = []\n",
    "tokenized_corpus_stemmed = []\n",
    "batch_size = 1000\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    batch = sentences[i:i+batch_size]\n",
    "    for sentence in tqdm(batch, desc=f\"Processing batch {i//batch_size + 1}\"):\n",
    "        lemmatized, stemmed = preprocess_sentence(sentence)\n",
    "        tokenized_corpus_lemmatized.append(lemmatized)\n",
    "        tokenized_corpus_stemmed.append(stemmed)\n",
    "\n",
    "print(\"\\nLemmatized sample:\", tokenized_corpus_lemmatized[:5])\n",
    "print(\"Stemmed sample:\", tokenized_corpus_stemmed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0707eee-004e-497e-a3bd-0ddadbea1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Çıktılardan veri seti oluşturma\n",
    "lemmatized_df = pd.DataFrame({\n",
    "    'original_sentence': sentences,\n",
    "    'processed_tokens': [' '.join(tokens) for tokens in tokenized_corpus_lemmatized]\n",
    "})\n",
    "\n",
    "stemmed_df = pd.DataFrame({\n",
    "    'original_sentence': sentences,\n",
    "    'processed_tokens': [' '.join(tokens) for tokens in tokenized_corpus_stemmed]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d4e0b47-f917-4c45-8157-a205551cddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files saved successfully:\n",
      "lemmatized_sentences.csv\n",
      "stemmed_sentences.csv\n"
     ]
    }
   ],
   "source": [
    "#CSV dosyası olarak kaydetme\n",
    "lemmatized_df.to_csv(r\"C:\\Users\\Elif\\desktop\\yapay_zeka_projesi\\lemmatized_sentences.csv\", index=False, encoding='utf-8-sig')\n",
    "stemmed_df.to_csv(r\"C:\\Users\\Elif\\desktop\\yapay_zeka_projesi\\stemmed_sentences.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\nFiles saved successfully:\")\n",
    "print(\"lemmatized_sentences.csv\")\n",
    "print(\"stemmed_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dced87ef-457f-4b94-b1ae-705303cdc3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümle 1 - Base: ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARALI OLUP ÖNÜ KAPANMAZ MUHTEŞEM SAKIZ ADASI MANZARALI 2+1 , 1+1 BAHÇELİ VE TERASLI DAİRELERDEN OLUŞAN PROJEDE KAPALI OTOPARK SPOR SALONU 7/24 GÜVENLİK AKILLI VE KONTROL MAKENİZMALI EV KONTROL SİSTEMİ VE  SONSUZLUK HAVUZU SİZLERİ BEKLİYOR.\n",
      "Cümle 1 - Lemmatized: ['Çeşme', 'mevkii', 'Full', 'de', 'olmak', 'ön', 'kapanmak', 'muhteşem', 'Bahçe', 'daire', 'oluşmak', 'proje', 'otopark', 'spor', 'salon', 'Güvenlik', 'Akil', 'kontrol', 'kontrol', 'sistem', 'sonsuz', 'havuz', 'siz', 'beklemek']\n",
      "Cümle 1 - Stemmed: ['çeşme', 'ayasara', 'mevkiin', 'full', 'de', 'manzarali', 'olup', 'ön', 'kapanmaz', 'muhteşe', 'sakiz', 'adasi', 'manzarali', 'bahçel', 'terasli', 'daire', 'oluşa', 'proje', 'kapali', 'otopark', 'spor', 'salo', 'güvenlik', 'akilli', 'kontrol', 'makenizmal', 'kontrol', 'siste', 'sonsuzluk', 'havuz', 'siz', 'bekliyor']\n",
      "\n",
      "\n",
      "Cümle 2 - Base: 4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRELERİMİZ KALMIŞTIR.\n",
      "Cümle 2 - Lemmatized: ['blok', 'oluşmak', 'proje', 'sinirli', 'daire']\n",
      "Cümle 2 - Stemmed: ['blok', 'oluşa', 'proje', 'sinirli', 'sayi', 'daire', 'kalmiş']\n",
      "\n",
      "\n",
      "Cümle 3 - Base: DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI GÖSTERMEKTEDİR.\n",
      "Cümle 3 - Lemmatized: ['daire', 'göre', 'fiyat', 'göstermek']\n",
      "Cümle 3 - Stemmed: ['daire', 'konum', 'gör', 'fiyat', 'farklilik', 'göstermek']\n",
      "\n",
      "\n",
      "Cümle 4 - Base: PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAPULU OLARAK SATIŞ OLACAĞI İÇİN KREDİYE UYGUN DEĞİLDİR.\n",
      "Cümle 4 - Lemmatized: ['proje', 'nitelik', 'olmak', 'his', 'tapu', 'olmak', 'kredi', 'uygun', 'değil']\n",
      "Cümle 4 - Stemmed: ['proje', 'resinde', 'nitelik', 'olup', 'his', 'tapul', 'olarak', 'satiş', 'olacaği', 'kredi', 'uygu', 'değil']\n",
      "\n",
      "\n",
      "Cümle 5 - Base: AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.\n",
      "Cümle 5 - Lemmatized: ['aidat', 'ödemek']\n",
      "Cümle 5 - Stemmed: ['aidat', 'ödemes', 'aylik', 'dir']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Cümle {i+1} - Base: {sentences[i]}\")   #cumlelerın ılk hallerı-metınde goruldugu hallerı (ham verı)\n",
    "    print(f\"Cümle {i+1} - Lemmatized: {tokenized_corpus_lemmatized[i]}\")  #cumlelerın lema hallerı \n",
    "    print(f\"Cümle {i+1} - Stemmed: {tokenized_corpus_stemmed[i]}\")  #cumlelerın Stem hallerı \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f25f5d-0bef-4c38-b7ac-31002a8b450e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>processed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARAL...</td>\n",
       "      <td>Çeşme mevkii Full de olmak ön kapanmak muhteşe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRE...</td>\n",
       "      <td>blok oluşmak proje sinirli daire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI...</td>\n",
       "      <td>daire göre fiyat göstermek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAP...</td>\n",
       "      <td>proje nitelik olmak his tapu olmak kredi uygun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.</td>\n",
       "      <td>aidat ödemek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_sentence  \\\n",
       "0  ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARAL...   \n",
       "1  4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRE...   \n",
       "2  DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI...   \n",
       "3  PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAP...   \n",
       "4                  AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.   \n",
       "\n",
       "                                    processed_tokens  \n",
       "0  Çeşme mevkii Full de olmak ön kapanmak muhteşe...  \n",
       "1                   blok oluşmak proje sinirli daire  \n",
       "2                         daire göre fiyat göstermek  \n",
       "3  proje nitelik olmak his tapu olmak kredi uygun...  \n",
       "4                                       aidat ödemek  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalem = pd.read_csv(\"lemmatized_sentences.csv\")\n",
    "datalem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e11069b-fb3c-4b70-85e7-d58ad39334d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e15edb3b-a7fd-43fa-815c-b8bb80a3133d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Çeşme mevkii Full de olmak ön kapanmak muhteşem Bahçe daire oluşmak proje otopark spor salon Güvenlik Akil kontrol kontrol sistem sonsuz havuz siz beklemek',\n",
       " 'blok oluşmak proje sinirli daire',\n",
       " 'daire göre fiyat göstermek']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ön işlenmiş token listelerini tekrar metine çeviriyoruz\n",
    "lemmatized_texts = [' '.join(tokens) for tokens in tokenized_corpus_lemmatized]\n",
    "\n",
    "lemmatized_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ae4fc82-1a6a-42fe-b5ba-afe8d2f6eb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aassm  abartmak  abd  abdi  abdullah  abdurrahim  abdurrahman  abdülhamid  \\\n",
      "0    0.0       0.0  0.0   0.0       0.0         0.0          0.0         0.0   \n",
      "1    0.0       0.0  0.0   0.0       0.0         0.0          0.0         0.0   \n",
      "2    0.0       0.0  0.0   0.0       0.0         0.0          0.0         0.0   \n",
      "3    0.0       0.0  0.0   0.0       0.0         0.0          0.0         0.0   \n",
      "4    0.0       0.0  0.0   0.0       0.0         0.0          0.0         0.0   \n",
      "\n",
      "   abdülhamit  abi  ...  şubat  şube  şule  şut  şömine  şöyle  şükraniye  \\\n",
      "0         0.0  0.0  ...    0.0   0.0   0.0  0.0     0.0    0.0        0.0   \n",
      "1         0.0  0.0  ...    0.0   0.0   0.0  0.0     0.0    0.0        0.0   \n",
      "2         0.0  0.0  ...    0.0   0.0   0.0  0.0     0.0    0.0        0.0   \n",
      "3         0.0  0.0  ...    0.0   0.0   0.0  0.0     0.0    0.0        0.0   \n",
      "4         0.0  0.0  ...    0.0   0.0   0.0  0.0     0.0    0.0        0.0   \n",
      "\n",
      "   şükür  şüphe  şık  \n",
      "0    0.0    0.0  0.0  \n",
      "1    0.0    0.0  0.0  \n",
      "2    0.0    0.0  0.0  \n",
      "3    0.0    0.0  0.0  \n",
      "4    0.0    0.0  0.0  \n",
      "\n",
      "[5 rows x 4922 columns]\n"
     ]
    }
   ],
   "source": [
    "#tf-idf vektöritizeri başlatma\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#tf-idf vektörlerini dönüştürür.\n",
    "tfidf_matrix = vectorizer.fit_transform(lemmatized_texts)\n",
    "\n",
    "#tf-idf vektörleştirme işleminde kullanılan tüm kelimelerin listesini döndürür.\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "#tf-idf matrisini pandas dataframeine dönüştürme\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "print(tfidf_df.head())\n",
    "\n",
    "tfidf_df.to_csv(\"tfidf_lemmatized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2d42c21-f3ba-4727-abef-e12c36b6aada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İlk cümlede en yüksek TF-IDF skoruna sahip 5 kelime:\n",
      "kontrol     0.494849\n",
      "sonsuz      0.319231\n",
      "akil        0.262493\n",
      "çeşme       0.250631\n",
      "kapanmak    0.215430\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#ilk cümlenin tf-idf skorlarını alma\n",
    "first_sentence_vector = tfidf_df.iloc[0]\n",
    "\n",
    "#skorları sıralama küçükten büyüğe\n",
    "top_5_words = first_sentence_vector.sort_values(ascending=False).head(5)\n",
    "\n",
    "print(\"İlk cümlede en yüksek TF-IDF skoruna sahip 5 kelime:\")\n",
    "print(top_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1315ad5e-7a78-490d-bcad-7d60784365b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balkon: 1.0000\n",
      "cam: 0.3620\n",
      "banyo: 0.3164\n",
      "âdet: 0.2534\n",
      "çift: 0.2401\n",
      "geniş: 0.2065\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#kelime vektörlerine bakacağız\n",
    "balkon_index = feature_names.tolist().index('balkon')\n",
    "\n",
    "balkon_vector = tfidf_matrix[:, balkon_index].toarray()\n",
    "\n",
    "tfidf_vectors = tfidf_matrix.toarray()\n",
    "\n",
    "similarities = cosine_similarity(balkon_vector.T, tfidf_vectors.T)\n",
    "\n",
    "similarities = similarities.flatten()\n",
    "top_5_indices = similarities.argsort()[-6:][::-1]\n",
    "\n",
    "for index in top_5_indices:\n",
    "    print(f\"{feature_names[index]}: {similarities[index]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ca3c2bf-539c-4f09-9e3e-2db04a508624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\elif\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\elif\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\elif\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\elif\\anaconda3\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\elif\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b45d80af-19b5-43ec-9f21-2842b370dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8409dabf-371c-4fce-9364-952e7d35a478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>processed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARAL...</td>\n",
       "      <td>çeşme ayasara mevkiin full de manzarali olup ö...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRE...</td>\n",
       "      <td>blok oluşa proje sinirli sayi daire kalmiş</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI...</td>\n",
       "      <td>daire konum gör fiyat farklilik göstermek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAP...</td>\n",
       "      <td>proje resinde nitelik olup his tapul olarak sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.</td>\n",
       "      <td>aidat ödemes aylik dir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_sentence  \\\n",
       "0  ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARAL...   \n",
       "1  4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRE...   \n",
       "2  DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI...   \n",
       "3  PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAP...   \n",
       "4                  AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.   \n",
       "\n",
       "                                    processed_tokens  \n",
       "0  çeşme ayasara mevkiin full de manzarali olup ö...  \n",
       "1         blok oluşa proje sinirli sayi daire kalmiş  \n",
       "2          daire konum gör fiyat farklilik göstermek  \n",
       "3  proje resinde nitelik olup his tapul olarak sa...  \n",
       "4                             aidat ödemes aylik dir  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastem = pd.read_csv(\"stemmed_sentences.csv\")\n",
    "datastem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3b87324-f56e-4e64-96e0-02dd5d7fcd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['çeşme ayasara mevkiin full de manzarali olup ön kapanmaz muhteşe sakiz adasi manzarali bahçel terasli daire oluşa proje kapali otopark spor salo güvenlik akilli kontrol makenizmal kontrol siste sonsuzluk havuz siz bekliyor',\n",
       " 'blok oluşa proje sinirli sayi daire kalmiş',\n",
       " 'daire konum gör fiyat farklilik göstermek']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_texts = [' '.join(tokens) for tokens in tokenized_corpus_stemmed]\n",
    "\n",
    "stemmed_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b088d7a-7156-4c8f-9bde-8b7d51695fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aalaça  aass  aaç  aba  abartılmamış  abdde  abdi  abdiipekçi  \\\n",
      "0     0.0   0.0  0.0  0.0           0.0    0.0   0.0         0.0   \n",
      "1     0.0   0.0  0.0  0.0           0.0    0.0   0.0         0.0   \n",
      "2     0.0   0.0  0.0  0.0           0.0    0.0   0.0         0.0   \n",
      "3     0.0   0.0  0.0  0.0           0.0    0.0   0.0         0.0   \n",
      "4     0.0   0.0  0.0  0.0           0.0    0.0   0.0         0.0   \n",
      "\n",
      "   abdulhamidha  abdullah  ...  şöm  şöminebarbeküjakuz  şöminel  şömineor  \\\n",
      "0           0.0       0.0  ...  0.0                 0.0      0.0       0.0   \n",
      "1           0.0       0.0  ...  0.0                 0.0      0.0       0.0   \n",
      "2           0.0       0.0  ...  0.0                 0.0      0.0       0.0   \n",
      "3           0.0       0.0  ...  0.0                 0.0      0.0       0.0   \n",
      "4           0.0       0.0  ...  0.0                 0.0      0.0       0.0   \n",
      "\n",
      "   şömines  şükrani  şükrü  şüphe  şık  şıklık  \n",
      "0      0.0      0.0    0.0    0.0  0.0     0.0  \n",
      "1      0.0      0.0    0.0    0.0  0.0     0.0  \n",
      "2      0.0      0.0    0.0    0.0  0.0     0.0  \n",
      "3      0.0      0.0    0.0    0.0  0.0     0.0  \n",
      "4      0.0      0.0    0.0    0.0  0.0     0.0  \n",
      "\n",
      "[5 rows x 17777 columns]\n"
     ]
    }
   ],
   "source": [
    "#tf-idf vektöritizeri başlatma\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#tf-idf vektörlerini dönüştürür.\n",
    "tfidf_matrix = vectorizer.fit_transform(stemmed_texts)\n",
    "\n",
    "#tf-idf vektörleştirme işleminde kullanılan tüm kelimelerin listesini döndürür.\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "#tf-idf matrisini pandas dataframeine dönüştürme\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "print(tfidf_df.head())\n",
    "tfidf_df.to_csv(\"tfidf_stemmed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f1a2d16-75bd-409f-b5d4-95dde6f73c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İlk cümlede en yüksek TF-IDF skoruna sahip 5 kelime:\n",
      "kontrol       0.402656\n",
      "manzarali     0.264930\n",
      "sakiz         0.253460\n",
      "makenizmal    0.253460\n",
      "ayasara       0.242597\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#ilk cümlenin tf-idf skorlarını alma\n",
    "first_sentence_vector = tfidf_df.iloc[0]\n",
    "\n",
    "#skorları sıralama (küçükten büyüğe)\n",
    "top_5_words = first_sentence_vector.sort_values(ascending=False).head(5)\n",
    "\n",
    "print(\"İlk cümlede en yüksek TF-IDF skoruna sahip 5 kelime:\")\n",
    "print(top_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcb0a09b-2644-45da-a18f-0eb5052052b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kat: 1.0000\n",
      "dair: 0.2258\n",
      "ar: 0.1910\n",
      "mülkiyetli: 0.1797\n",
      "banyo: 0.1771\n",
      "bina: 0.1610\n"
     ]
    }
   ],
   "source": [
    "#kelime vektörlerine bakacağız\n",
    "kat_index = feature_names.tolist().index('kat')\n",
    "\n",
    "kat_vector = tfidf_matrix[:, kat_index].toarray()\n",
    "\n",
    "tfidf_vectors = tfidf_matrix.toarray()\n",
    "\n",
    "similarities = cosine_similarity(kat_vector.T, tfidf_vectors.T)\n",
    "\n",
    "similarities = similarities.flatten()\n",
    "top_5_indices = similarities.argsort()[-6:][::-1]\n",
    "\n",
    "for index in top_5_indices:\n",
    "    print(f\"{feature_names[index]}: {similarities[index]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "820b7f77-ae5d-419e-8132-e076a2840318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>processed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARAL...</td>\n",
       "      <td>Çeşme mevkii Full de olmak ön kapanmak muhteşe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRE...</td>\n",
       "      <td>blok oluşmak proje sinirli daire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI...</td>\n",
       "      <td>daire göre fiyat göstermek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAP...</td>\n",
       "      <td>proje nitelik olmak his tapu olmak kredi uygun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.</td>\n",
       "      <td>aidat ödemek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_sentence  \\\n",
       "0  ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARAL...   \n",
       "1  4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRE...   \n",
       "2  DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI...   \n",
       "3  PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAP...   \n",
       "4                  AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.   \n",
       "\n",
       "                                    processed_tokens  \n",
       "0  Çeşme mevkii Full de olmak ön kapanmak muhteşe...  \n",
       "1                   blok oluşmak proje sinirli daire  \n",
       "2                         daire göre fiyat göstermek  \n",
       "3  proje nitelik olmak his tapu olmak kredi uygun...  \n",
       "4                                       aidat ödemek  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalem = pd.read_csv(\"lemmatized_sentences.csv\")\n",
    "datalem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e480641-65f9-49aa-b801-110a8d8d458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatized_model_cbow_window2_dim100 model saved!\n",
      "lemmatized_model_skipgram_window2_dim100 model saved!\n",
      "lemmatized_model_cbow_window4_dim100 model saved!\n",
      "lemmatized_model_skipgram_window4_dim100 model saved!\n",
      "lemmatized_model_cbow_window2_dim300 model saved!\n",
      "lemmatized_model_skipgram_window2_dim300 model saved!\n",
      "lemmatized_model_cbow_window4_dim300 model saved!\n",
      "lemmatized_model_skipgram_window4_dim300 model saved!\n",
      "stemmed_model_cbow_window2_dim100 model saved!\n",
      "stemmed_model_skipgram_window2_dim100 model saved!\n",
      "stemmed_model_cbow_window4_dim100 model saved!\n",
      "stemmed_model_skipgram_window4_dim100 model saved!\n",
      "stemmed_model_cbow_window2_dim300 model saved!\n",
      "stemmed_model_skipgram_window2_dim300 model saved!\n",
      "stemmed_model_cbow_window4_dim300 model saved!\n",
      "stemmed_model_skipgram_window4_dim300 model saved!\n"
     ]
    }
   ],
   "source": [
    "parameters = [\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 300}\n",
    "]\n",
    "\n",
    "def train_and_save_model(corpus, params, model_name):\n",
    "    model = Word2Vec(corpus, vector_size=params['vector_size'], window=params['window'], min_count=1, sg=1 if params['model_type'] == 'skipgram' else 0)\n",
    "    model.save(f\"{model_name}_{params['model_type']}_window{params['window']}_dim{params['vector_size']}.model\")\n",
    "    print(f\"{model_name}_{params['model_type']}_window{params['window']}_dim{params['vector_size']} model saved!\")\n",
    "\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_lemmatized, param, \"lemmatized_model\")\n",
    "\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_stemmed, param, \"stemmed_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cbdbd8c-23a5-4a0b-8071-a01d3b8909e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7279a27b-4620-4500-83bc-ce3553cdd05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized CBOW Window 2 Dim 100 Modeli - 'balkon' ile En Benzer 3 Kelime:\n",
      "Kelime: cam, Benzerlik Skoru: 0.9915151596069336\n",
      "Kelime: tuvalet, Benzerlik Skoru: 0.9901226162910461\n",
      "Kelime: teras, Benzerlik Skoru: 0.9874627590179443\n",
      "\n",
      "Stemmed Skipgram Window 4 Dim 100 Modeli - 'balkon' ile En Benzer 3 Kelime:\n",
      "Kelime: teras, Benzerlik Skoru: 0.9620236158370972\n",
      "Kelime: kapatil, Benzerlik Skoru: 0.9579077363014221\n",
      "Kelime: odalari, Benzerlik Skoru: 0.9566958546638489\n",
      "\n",
      "Lemmatized Skipgram Window 2 Dim 300 Modeli - 'balkon' ile En Benzer 3 Kelime:\n",
      "Kelime: tuvalet, Benzerlik Skoru: 0.9535260200500488\n",
      "Kelime: teras, Benzerlik Skoru: 0.9505287408828735\n",
      "Kelime: kiler, Benzerlik Skoru: 0.9496369957923889\n"
     ]
    }
   ],
   "source": [
    "model_1 = Word2Vec.load(\"lemmatized_model_cbow_window2_dim100.model\")\n",
    "model_2 = Word2Vec.load(\"stemmed_model_skipgram_window4_dim100.model\")\n",
    "model_3 = Word2Vec.load(\"lemmatized_model_skipgram_window2_dim300.model\")\n",
    "\n",
    "def print_similar_words(model, model_name):\n",
    "    similarity = model.wv.most_similar('balkon', topn=3)\n",
    "    print(f\"\\n{model_name} Modeli - 'balkon' ile En Benzer 3 Kelime:\")\n",
    "    for word, score in similarity:\n",
    "        print(f\"Kelime: {word}, Benzerlik Skoru: {score}\")\n",
    "\n",
    "print_similar_words(model_1, \"Lemmatized CBOW Window 2 Dim 100\")\n",
    "print_similar_words(model_2, \"Stemmed Skipgram Window 4 Dim 100\")\n",
    "print_similar_words(model_3, \"Lemmatized Skipgram Window 2 Dim 300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87330623-c816-4247-9bd0-d99bfb9bc8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>processed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARAL...</td>\n",
       "      <td>çeşme ayasara mevkiin full de manzarali olup ö...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRE...</td>\n",
       "      <td>blok oluşa proje sinirli sayi daire kalmiş</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI...</td>\n",
       "      <td>daire konum gör fiyat farklilik göstermek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAP...</td>\n",
       "      <td>proje resinde nitelik olup his tapul olarak sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.</td>\n",
       "      <td>aidat ödemes aylik dir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_sentence  \\\n",
       "0  ÇEŞME AYASARANDA MEVKİİNDE FULL DENİZ MANZARAL...   \n",
       "1  4 BLOKTAN OLUŞAN PROJEDE  SINIRLI SAYIDA DAİRE...   \n",
       "2  DAİRELERİMİZ KONUMLARINA GÖRE FİYAT FARKLILIĞI...   \n",
       "3  PROJEMİZ RESİNDENCE NİTELİĞİNDE OLUP HİSSE TAP...   \n",
       "4                  AİDAT ÖDEMESİ AYLIK 2.500 TL DİR.   \n",
       "\n",
       "                                    processed_tokens  \n",
       "0  çeşme ayasara mevkiin full de manzarali olup ö...  \n",
       "1         blok oluşa proje sinirli sayi daire kalmiş  \n",
       "2          daire konum gör fiyat farklilik göstermek  \n",
       "3  proje resinde nitelik olup his tapul olarak sa...  \n",
       "4                             aidat ödemes aylik dir  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastem = pd.read_csv(\"stemmed_sentences.csv\")\n",
    "datastem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bf80089-c33e-4695-9931-06ca4c4e7512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatized_model_cbow_window2_dim100 model saved!\n",
      "lemmatized_model_skipgram_window2_dim100 model saved!\n",
      "lemmatized_model_cbow_window4_dim100 model saved!\n",
      "lemmatized_model_skipgram_window4_dim100 model saved!\n",
      "lemmatized_model_cbow_window2_dim300 model saved!\n",
      "lemmatized_model_skipgram_window2_dim300 model saved!\n",
      "lemmatized_model_cbow_window4_dim300 model saved!\n",
      "lemmatized_model_skipgram_window4_dim300 model saved!\n",
      "stemmed_model_cbow_window2_dim100 model saved!\n",
      "stemmed_model_skipgram_window2_dim100 model saved!\n",
      "stemmed_model_cbow_window4_dim100 model saved!\n",
      "stemmed_model_skipgram_window4_dim100 model saved!\n",
      "stemmed_model_cbow_window2_dim300 model saved!\n",
      "stemmed_model_skipgram_window2_dim300 model saved!\n",
      "stemmed_model_cbow_window4_dim300 model saved!\n",
      "stemmed_model_skipgram_window4_dim300 model saved!\n"
     ]
    }
   ],
   "source": [
    "parameters = [\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 300}\n",
    "]\n",
    "\n",
    "def train_and_save_model(corpus, params, model_name):\n",
    "    model = Word2Vec(corpus, vector_size=params['vector_size'], window=params['window'], min_count=1, sg=1 if params['model_type'] == 'skipgram' else 0)\n",
    "    model.save(f\"{model_name}_{params['model_type']}_window{params['window']}_dim{params['vector_size']}.model\")\n",
    "    print(f\"{model_name}_{params['model_type']}_window{params['window']}_dim{params['vector_size']} model saved!\")\n",
    "\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_lemmatized, param, \"lemmatized_model\")\n",
    "\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_stemmed, param, \"stemmed_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "121bd74f-0fe0-4e2c-95b3-b1d7c9fad9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized CBOW Window 2 Dim 100 Modeli - 'kat' ile En Benzer 3 Kelime:\n",
      "Kelime: bina, Benzerlik Skoru: 0.972588062286377\n",
      "Kelime: iki, Benzerlik Skoru: 0.9691206812858582\n",
      "Kelime: katil, Benzerlik Skoru: 0.9667516946792603\n",
      "\n",
      "Stemmed Skipgram Window 4 Dim 100 Modeli - 'kat' ile En Benzer 3 Kelime:\n",
      "Kelime: kati, Benzerlik Skoru: 0.8913896083831787\n",
      "Kelime: sayis, Benzerlik Skoru: 0.8855994343757629\n",
      "Kelime: yaşi, Benzerlik Skoru: 0.8834439516067505\n",
      "\n",
      "Lemmatized Skipgram Window 2 Dim 300 Modeli - 'kat' ile En Benzer 3 Kelime:\n",
      "Kelime: iki, Benzerlik Skoru: 0.9262877106666565\n",
      "Kelime: katı, Benzerlik Skoru: 0.9251409769058228\n",
      "Kelime: yaş, Benzerlik Skoru: 0.9088300466537476\n"
     ]
    }
   ],
   "source": [
    "model_1 = Word2Vec.load(\"lemmatized_model_cbow_window2_dim100.model\")\n",
    "model_2 = Word2Vec.load(\"stemmed_model_skipgram_window4_dim100.model\")\n",
    "model_3 = Word2Vec.load(\"lemmatized_model_skipgram_window2_dim300.model\")\n",
    "\n",
    "def print_similar_words(model, model_name):\n",
    "    similarity = model.wv.most_similar('kat', topn=3)\n",
    "    print(f\"\\n{model_name} Modeli - 'kat' ile En Benzer 3 Kelime:\")\n",
    "    for word, score in similarity:\n",
    "        print(f\"Kelime: {word}, Benzerlik Skoru: {score}\")\n",
    "\n",
    "print_similar_words(model_1, \"Lemmatized CBOW Window 2 Dim 100\")\n",
    "print_similar_words(model_2, \"Stemmed Skipgram Window 4 Dim 100\")\n",
    "print_similar_words(model_3, \"Lemmatized Skipgram Window 2 Dim 300\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
